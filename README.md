# ğŸ¯ Veille Technologique : Analyse de Sentiments avec Hugging Face

## ğŸ“‹ Description du Projet

Ce projet rÃ©alise une veille technologique et un benchmark de services d'analyse de sentiments proposÃ©s par Hugging Face. Il s'inscrit dans le cadre d'une certification en intelligence artificielle (Bloc de compÃ©tence 2 - E2).

### Objectifs
- **Fonctionnel :** Proposer un service d'IA capable de dÃ©tecter le sentiment d'un texte court
- **Technique :** Comparer 3 modÃ¨les d'analyse de sentiments sur Hugging Face
- **PÃ©dagogique :** DÃ©montrer les compÃ©tences C6, C7 et C8 de la certification

## ğŸš€ Installation et Utilisation

### PrÃ©requis
- Python 3.8 ou supÃ©rieur
- 4 GB de RAM minimum (pour les modÃ¨les locaux)
- Connexion internet (pour tÃ©lÃ©charger les modÃ¨les)

### Installation

1. **Cloner le projet :**
```bash
git clone [url-du-repo]
cd rendu_e2
```

2. **Installer les dÃ©pendances :**
```bash
pip install -r requirements.txt
```

3. **Lancer le benchmark :**
```bash
python sentiment_analysis_benchmark.py
```

### Modes d'ExÃ©cution

Le script propose deux modes de test :

1. **Mode Local (RecommandÃ©)**
   - TÃ©lÃ©charge et utilise les modÃ¨les en local
   - Pas de limite de requÃªtes
   - Premier lancement plus long (tÃ©lÃ©chargement des modÃ¨les)

2. **Mode API (Gratuit)**
   - Utilise l'API Hugging Face
   - Limite de 30 requÃªtes/jour
   - Plus rapide pour les tests ponctuels

## ğŸ“Š ModÃ¨les TestÃ©s

### 1. DistilBERT English
- **ModÃ¨le :** `distilbert-base-uncased-finetuned-sst-2-english`
- **Langues :** Anglais uniquement
- **Classification :** Binaire (positif/nÃ©gatif)
- **Avantages :** Rapide, prÃ©cis, lÃ©ger
- **Taille :** 268 MB

### 2. BERT Multilingue
- **ModÃ¨le :** `nlptown/bert-base-multilingual-uncased-sentiment`
- **Langues :** EN, FR, DE, ES, IT
- **Classification :** 5 Ã©toiles (converti en positif/neutre/nÃ©gatif)
- **Avantages :** Multilingue, granulaire
- **Taille :** 438 MB

### 3. RoBERTa Twitter
- **ModÃ¨le :** `cardiffnlp/twitter-roberta-base-sentiment`
- **Langues :** Anglais uniquement
- **Classification :** Ternaire (positif/neutre/nÃ©gatif)
- **Avantages :** OptimisÃ© rÃ©seaux sociaux
- **Taille :** 499 MB

## ğŸ“ˆ RÃ©sultats Attendus

Le script gÃ©nÃ¨re :

1. **Tableau comparatif** en console
2. **Graphiques** sauvegardÃ©s dans `benchmark_results.png`
3. **RÃ©sultats dÃ©taillÃ©s** dans `detailed_results.json`
4. **Recommandations** d'usage

### Exemple de Sortie
```
ğŸ¯ BENCHMARK D'ANALYSE DE SENTIMENTS - HUGGING FACE
============================================================

ğŸ“Š Test du modÃ¨le: distilbert-english
----------------------------------------
âœ… Temps de rÃ©ponse moyen: 0.152s
âœ… Nombre de tests rÃ©ussis: 10
   Exemple 1: 'This product is absolutely amazing! I love it!' â†’ POSITIVE (0.99)
   Exemple 2: 'The service was terrible and the staff was rude.' â†’ NEGATIVE (0.98)
   Exemple 3: 'It's okay, nothing special but works fine.' â†’ POSITIVE (0.67)
```

## ğŸ“ Structure du Projet

```
rendu_e2/
â”œâ”€â”€ sentiment_analysis_benchmark.py  # Script principal
â”œâ”€â”€ requirements.txt                  # DÃ©pendances Python
â”œâ”€â”€ README.md                        # Documentation
â”œâ”€â”€ synthese_veille.md              # SynthÃ¨se de veille
â”œâ”€â”€ contexte.txt                     # Contexte du projet
â”œâ”€â”€ benchmark_results.png            # Graphiques (gÃ©nÃ©rÃ©)
â””â”€â”€ detailed_results.json            # RÃ©sultats dÃ©taillÃ©s (gÃ©nÃ©rÃ©)
```

## ğŸ”§ Personnalisation

### Ajouter de Nouveaux ModÃ¨les

Modifiez la section `self.models` dans `sentiment_analysis_benchmark.py` :

```python
'nouveau-modele': {
    'name': 'nom/du-modele-huggingface',
    'languages': ['en', 'fr'],
    'description': 'Description du modÃ¨le',
    'expected_accuracy': 'XX.X%',
    'model_size_mb': 300,
    'api_endpoint': 'https://api-inference.huggingface.co/models/nom/du-modele'
}
```

### Modifier les Exemples de Test

Ã‰ditez `self.test_samples` pour ajouter vos propres phrases de test :

```python
self.test_samples = {
    'en': [
        "Votre phrase en anglais",
        # ...
    ],
    'fr': [
        "Votre phrase en franÃ§ais",
        # ...
    ]
}
```

## ğŸ“š CompÃ©tences DÃ©montrÃ©es

### C6 : Organisation d'une veille technologique
- âœ… SÃ©lection ciblÃ©e de modÃ¨les pertinents
- âœ… Documentation structurÃ©e des rÃ©sultats
- âœ… SynthÃ¨se comparative

### C7 : Benchmark de services IA
- âœ… Comparaison quantitative (temps, prÃ©cision)
- âœ… Ã‰valuation qualitative (accessibilitÃ©, documentation)
- âœ… Recommandations d'usage

### C8 : ParamÃ©trage via API
- âœ… IntÃ©gration avec l'API Hugging Face
- âœ… Utilisation des pipelines Transformers
- âœ… Gestion des erreurs et limites

## ğŸš¨ DÃ©pannage

### Erreurs Courantes

1. **"CUDA out of memory"**
   - Solution : Utilisez le mode CPU ou rÃ©duisez la taille des modÃ¨les

2. **"Model not found"**
   - Solution : VÃ©rifiez la connexion internet et le nom du modÃ¨le

3. **"API rate limit exceeded"**
   - Solution : Passez en mode local ou attendez le lendemain

### Optimisations

- **Premier lancement :** Les modÃ¨les sont tÃ©lÃ©chargÃ©s (~1.5 GB)
- **Lancements suivants :** Utilisation des modÃ¨les en cache
- **Mode API :** Plus rapide mais limitÃ© Ã  30 requÃªtes/jour

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans le cadre d'une certification en intelligence artificielle.

## ğŸ‘¨â€ğŸ’» Auteur

Kevin Packianathan - Certification IA - Bloc de compÃ©tence 2 - E2

